# Language models seem to be much better than humans at next-token prediction

This repo contains the data and scrappy notebooks analyzing the results for experiments made for [this post](https://www.alignmentforum.org/posts/htrZrxduciZ5QaCjw/language-models-seem-to-be-much-better-than-humans-at-next).

Ideas for these experiments are mostly not mine, but mistakes in the code and in the math are.
